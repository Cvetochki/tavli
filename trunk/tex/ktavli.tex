\documentclass[a4paper,11pt]{book}
%\usepackage[utf8ttf]{inputenc}
\usepackage[english,greek]{babel}
\usepackage[iso-8859-7]{inputenc}
\usepackage{indentfirst} 
\usepackage{color}
%\usepackage{amsfonts}
%\usepackage{amsmath}
%\usepackage{amssymb}
%\usepackage{amsthm}
\usepackage[dvips]{graphicx}
\usepackage{float}
%\usepackage{times}
%\usepackage[T1]{fontenc}
\usepackage{fancyvrb}
\usepackage{listings}
\definecolor{Brown}{cmyk}{0,0.81,1,0.60}
%\definecolor{OliveGreen}{cmyk}{0.64,0,0.95,0.40}
\definecolor{OliveGreen}{rgb}{0.00,0.60,0.00}
\definecolor{CadetBlue}{cmyk}{0.62,0.57,0.23,0}
\lstset{language=TeX}
\usepackage{a4wide}
%\lstset{labelstep=1, labelsep=5pt}
% \lstset{
% 	basicstyle=\small,
% 	identifierstyle=,
% 	keywordstyle=\color{green}\bfseries\underbar,
% 	commentstyle=\color{brown},
% 	stringstyle=\ttfamily
% }

%\usepackage{ae}
\let\ORIGtextgreek=\textgreek
\renewcommand{\textgreek}[1]{{ \fontfamily{cmr}\selectfont\OR IGtextgreek{#1}}}
\let\ORIGgreektext=\greektext
\renewcommand{\greektext}{\fontfamily{cmr}\ORIGgreektext}
\newcommand{\eng}[1]{%
        \selectlanguage{english}#1\selectlanguage{greek}%
}
% Title Page
\title{\textbf{\begin{Huge}\eng{ktavli}\end{Huge}}}

\author{Αλκίνοος Αλέξανδρος Αργυρόπουλος}
\date{Αύγουστος 2005}
\begin{document}
%\lstset{language=C++} %activate C++
\lstset{language=C++,
%frame=ltrb,framesep=5pt,
 basicstyle=\small,
 keywordstyle=\ttfamily\color{OliveGreen}\bfseries,
 identifierstyle=\ttfamily\color{CadetBlue}, 
 commentstyle=\color{Brown},
 stringstyle=\ttfamily,
 numbers=left,
 numberstyle=\color[rgb]{0.50,0.00,0.00}\ttfamily\small,
 escapeinside=@`,
 showstringspaces=true}
\maketitle
\tableofcontents
% \begin{abstract}
% Προσπάθεια υλοποίησης της τεχνικής του \selectlanguage{english}Gerald Tesauro  \textit{Temporal Difference Learning and TD-Gammon}\selectlanguage{greek} με σκοπό τη δημιουργία του καλύτερου ελληνικού τάβλι.
% \end{abstract}
\chapter{Εισαγωγή}
Πάντα ήθελα να φτιάξω ένα καλό πρόγραμμα για τάβλι.  Αρκετά παλιά, σε μια \selectlanguage{english}Amiga\selectlanguage{greek} 1200, όταν είχα αρχίσει να μαθαίνω \selectlanguage{english}C\selectlanguage{greek} είχα φτιάξει ένα απλό τάβλι (έπαιζε μόνο πόρτες) και η (υποτυπώδης) \textit{νοημοσύνη} του ήταν απλά ένα σύνολο κανόνων.  Το αποτέλεσμα ήταν καλό.  Δεν έπαιζε άριστα, άλλα έπαιζε καλά.

Τα χρόνια πέρασαν.  Άφησα την \selectlanguage{english}Amiga\selectlanguage{greek} και σιγά-σιγά πέρασα από την \selectlanguage{english}C\selectlanguage{greek} στην \selectlanguage{english}C++\selectlanguage{greek} και από τα \selectlanguage{english}Windows\selectlanguage{greek} σε \selectlanguage{english}Linux\selectlanguage{greek}.  Έχουν περάσει αρκετά χρόνια από εκείνο το πρωτόγονο πείραμα στην \selectlanguage{english}Amiga\selectlanguage{greek} και τώρα θέλω να φτιάξω κάτι καλύτερο, κάτι πιο ολοκληρωμένο.  Στην Ελλάδα παίζουμε τρία διαφορετικά παιχνίδια στο τάβλι, και για όσους δεν τα ξέρουν αυτά είναι:

\begin{itemize}
\item Πόρτες, σχεδόν σαν το \selectlanguage{english}backgammon\selectlanguage{greek} που έχουν οι δυτικοί
\item Πλακωτό, που σκοπός είναι να αιχμαλωτίσεις τον αντίπαλο
\item Φεύγα, στρατηγική παρεμπόδισης και τρεχάλας
\end{itemize}

Το να γράψω ένα πλήρες πρόγραμμα και για τα τρία παιχνίδια είναι μια καλή πρόκληση.  Να δημιουργήσω τρεις διαφορετικές Τεχνητές Νοημοσύνες που κάθε μία να ανταποκρίνεται και σε ένα παιχνίδι είναι ακόμα μεγαλύτερη πρόκληση.  Τόσο μεγάλη που συνεχώς ήμουν αναβλητικός με τον σχεδιασμό του έργου.  Μία μέρα, σαν όλες τις άλλες, έψαχνα στο \selectlanguage{english}internet\selectlanguage{greek} για τεχνητή νοημοσύνη και κάποια στιγμή έφτασα στο \selectlanguage{english}site\selectlanguage{greek} της \selectlanguage{english}IBM\selectlanguage{greek} όπου υπάρχει μια εργασία του \selectlanguage{english}Gerald Tesauro\footnote{http://www.research.ibm.com/massive/tdl.html}\selectlanguage{greek}.  Δεν ήταν η πρώτη φορά που τη διάβαζα, αλλά αυτή τη φορά προσπάθησα πραγματικά να καταλάβω την καινοτομία της.  Και αυτή τη φορά τα κατάφερα! (Νομίζω...)

Εντυπωσιάστηκα!  Βλέπετε, όταν πριν χρόνια είχα φτιάξει τις πόρτες, αυτό που είχα κάνει ήταν να βάλω, από την όποια γνώση του παιχνιδιού είχα, ότι νόμιζα πως ήταν σημαντικό. Το εκπληκτικό της τεχνικής \selectlanguage{english}\textit{Temporal Difference Learning}\selectlanguage{greek} είναι ότι δεν χρειάζεται καθόλου γνώση.  Φτιάχνεις το πρόγραμμα και αυτό θα βρει μόνο του τη γνώση. Το νευρωνικό δίκτυο (ΝΝ για συντομία από τα αρχικά του στην αγγλική γλώσσα) παίζει παρτίδες μόνο του με τον εαυτό του και μαθαίνει μόνο του.  Απίστευτα πράγματα, αν το καλοσκεφτείτε.  Αυτό επίσης έχει την πολύ συμφέρουσα συνέπεια ότι αφού δεν έχει κωδικοποιημένη μέσα του τη γνώση του παιχνιδιού τότε μπορεί όμορφα και ωραία να \textit{μάθει} και τα τρία παιχνίδια.  Πως σας φαίνεται αυτό?
\chapter{Νευρωνικά Δίκτυα}
\section{Νευρώνας}
Τα νευρωνικά δίκτυα (\eng{Neural Network} -- NN για συντομία) είναι η προσπάθεια αναπαράστασης των νευρώνων που συναντάμε στον εγκέφαλο του ανθρώπου (και άλλων ζώων) στο χώρο του προγραμματισμού.
\begin{figure}
   \begin{minipage}[t]{0.5\linewidth}
	\centering
	\includegraphics[width=2in]{pneuron.eps}
	\caption{Βιολογικός νευρώνας} \label{fig:pn}
   \end{minipage}%
   \begin{minipage}[t]{0.5\linewidth}
	\centering
	\includegraphics[width=2in]{neuron.eps}
	\caption{Τεχνητός νευρώνας} \label{fig:an}
   \end{minipage}
\end{figure}

Κάθε βιολογικός νευρώνας (Σχήμα \ref{fig:pn}) έχει πολλές συνδέσεις με άλλους νευρώνες (συνάψεις).  Οι συνδέσεις αυτές λειτουργούν ως είσοδοι (\eng{inputs}).  Όταν οι είσοδοι έχουν τις \emph{κατάλληλες} τιμές, τότε ο νευρώνας \emph{ενεργοποιείται} (\eng{fires}), και αυτή η \emph{ενεργοποίηση} περνάει ως (τμήμα) εισόδου σε άλλους νευρώνες, αλλά για τον συγκεκριμένο νευρώνα είναι έξοδοι (\eng{outputs}).  Ενδεικτικά, ο ανθρώπινος εγκέφαλος έχει δέκα δισεκατομμύρια νευρώνες.

Συνεπώς, ένας \emph{τεχνητός} νευρώνας, χρειάζεται εισόδους \eng{x}, έστω \eng{n} το πλήθος τους.
\begin{eqnarray}
\eng{x_1,x_2,x_3 \ldots x_n} \nonumber
\end{eqnarray}

Κάθε είσοδος έχει διαφορετικό βάρος ανάλογα με το οποίο επηρεάζει τον νευρώνα. Έστω \eng{w} το βάρος, και πάλι \eng{n} το πλήθος τους.
\begin{eqnarray}
\eng{w_1,w_2,w_3 \ldots w_n} \nonumber
\end{eqnarray}

Αν συνδυάσουμε τις εισόδους με τα βάρη τότε αυτά μας δίνουν μια τιμή στο νευρώνα που περιγράφεται από το παρακάτω άθροισμα:
\selectlanguage{english}
\begin{eqnarray}
w_1x_1+w_2x_2+w_3x_3+ \cdots +w_nx_n \nonumber
\end{eqnarray}
\selectlanguage{greek}

Το άθροισμα αυτό έχει την εξής, πιο σύντομη, μαθηματική απεικόνιση:
\selectlanguage{english}
\begin{eqnarray}
\sum \limits_{i=1}^{n} w_{i}x_{i} \label{eq:sum}
\end{eqnarray}
\selectlanguage{greek}
% \begin{figure}
%    \centering
%    \includegraphics[width=2in]{neuron.eps}
%    \caption{Τεχνητός νευρώνας}
%    \label{fig:graph}
% \end{figure}

Χρειαζόμαστε άλλη μία τιμή, που θα καθορίζει πότε ο νευρώνας θα ενεργοποιείται.  Αν ξεπεράσει μια τιμή, το κατώφλι, τότε θα ενεργοποιείται, δηλαδή οι έξοδοι θα έχουν την τιμή 1, αλλιώς δεν θα ενεργοποιείται, δηλαδή οι έξοδοι θα έχουν την τιμή 0.  Αφού μιλάμε για κατώφλι (\eng{threshold}) ας το συμβολίσουμε με το γράμμα Κ.
\begin{eqnarray}
\sum \limits_{i=1}^{n} w_{i}x_{i}  & \geq & K, \Rightarrow 1 \mbox{ (Ενεργοποίηση) } \nonumber \\
\sum \limits_{i=1}^{n} w_{i}x_{i}  & < & K, \Rightarrow 0 \mbox{ (Μη Ενεργοποίηση) }
\end{eqnarray}

Ας δούμε τώρα πως αυτό γίνεται σε \eng{C/C++}. Έστω \eng{w[n]} και \eng{x[n]} πίνακες που έχουν τις τιμές για τα βάρη και τις εισόδους αντίστοιχα.
\floatstyle{ruled}
\newfloat{Πρόγραμμα}{thp}{lo}
\floatname{Πρόγραμμα}{Πρόγραμμα}
\begin{Πρόγραμμα}
\selectlanguage{english}
\begin{lstlisting}{}
double activation = 0;
for(int i=0; i<n; ++i)
  activation += w[i]*x[i];
if (activation >= k)
  activation = 1;
else
  activation = 0;
\end{lstlisting}
\selectlanguage{greek}
  \caption{ - Λειτουργία του νευρώνα σε \eng{C/C++}}
  \label{prg1}
\end{Πρόγραμμα}


\section{Πολλοί νευρώνες σε...δίκτυο}
Είδαμε τι είναι ένας τεχνητός νευρώνας και πως περίπου λειτουργεί.  Τι είναι όμως τα Νευρωνικά Δίκτυα?

Όπως οι βιολογικοί νευρώνες συνδέονται με άλλους νευρώνες, το ίδιο μπορούμε να κάνουμε και με τους τεχνητούς νευρώνες.  Υπάρχουν πάρα πολλοί τρόποι για να συνδέσουμε τους νευρώνες.  Κάθε διαφορετικός τρόπος μας δίνει και μια διαφορετική τοπολογία του δικτύου.  Ο πιο σύνηθες και διαδεδομένος τρόπος σύνδεσης είναι αυτός που φαίνεται στο σχήμα \ref{fig:nn}.  Παρατηρώντας το δίκτυο αυτό βλέπετε τρία διακριτά σημεία.

\begin{itemize}
\item Επίπεδο εισόδου, όπου εδώ το δίκτυο διαβάζει τις εισόδους (\eng{inputs}).  Κάθε είσοδος συνδέεται με \emph{όλους} τους νευρώνες του επόμενου επιπέδου.
\item Επίπεδο κρυμμένο, οι νευρώνες αυτοί παίρνουν είσοδο από τις εισόδους και δίνουν έξοδο στο επόμενο επίπεδο νευρώνων.  Και πάλι κάθε νευρώνας συνδέεται στην έξοδο με όλους τους νευρώνες του επόμενου επιπέδου.
\item Επίπεδο εξόδου, εδώ παίρνουν είσοδο την έξοδο του προηγούμενου επίπεδου και δίνουν την τελική έξοδο.
\end{itemize}
\begin{figure}
    \centering
    \includegraphics[width=4in]{nn.eps}
    \caption{Νευρωνικό Δίκτυο}
    \label{fig:nn}
\end{figure}

Αυτό που θα δοκιμάσουμε να κάνουμε είναι να \emph{εκπαιδεύσουμε} ένα ΝΝ, ώστε όταν του δίνουμε ως είσοδο τη διάταξη που έχουν τα πούλια στην ταβλιέρα, αυτό να μας δίνει ως έξοδο την πιθανότητα νίκης της πλευράς που έχει σειρά να παίξει.  Δηλαδή θα δίνει ως έξοδο ένα πραγματικό αριθμό από 0 έως 1.  Αν για παράδειγμα η έξοδος είναι 0.625 τότε θα σημαίνει ότι η πλευρά που είναι σειρά της να παίξει έχει 62.5\% πιθανότητες να κερδίσει.

\section{Σιγμοειδής συνάρτηση}
Είδαμε πριν όμως ότι ένας νευρώνας μπορεί να έχει την τιμή 1 ή 0.  Πως λοιπόν μπορούμε να πάρουμε από έναν νευρώνα πραγματικό αριθμό?

Μιλήσαμε για ένα κατώφλι που όταν η τιμή του νευρώνα το ξεπεράσει τότε η έξοδος γίνεται 1, ενώ αν δεν το ξεπεράσει η έξοδος γίνεται 0.  Αν αφαιρέσουμε το κατώφλι, τότε χρειαζόμαστε μια συνάρτηση που να μας δίνει τιμές από 0 έως 1, ανάλογα με το άθροισμα των γινομένων των βαρών επί των εισόδων. (τύπος \ref{eq:sum}, σελίδα \pageref{eq:sum})
\begin{figure}
    \centering
    \includegraphics[width=4in]{sigmoid.eps}
    \caption{Σιγμοειδής συνάρτηση}
    \label{fig:sigmoid}
\end{figure}

Υπάρχουν αρκετές συναρτήσεις που θα μπορούσαμε να χρησιμοποιήσουμε, αλλά εμείς θα χρησιμοποιήσουμε την \emph{σιγμοειδή συνάρτηση} (\eng{sigmoid function}).  Η συνάρτηση αυτή είναι:
\begin{eqnarray}
\mbox{Έξοδος} = \frac{1}{1+e^{-\frac{x}{a}}} \label{eq:sigmoid}
\end{eqnarray}

Όπως φαίνεται και στο γράφημα (σχήμα \ref{fig:sigmoid}\footnote{Για το γράφημα χρησιμοποιήθηκε η εφαρμογή \eng{gnuplot}, η συνάρτηση \eng{exp(x)} είναι η $e^x$}) ανάλογα με την τιμή του \eng{$a$} προκύπτει και το πόσο απότομη ή απαλή θα είναι και συμπεριφορά της συνάρτησης.  Σε όλες τις περιπτώσεις όμως μας δίνει τιμές από 0 έως 1.

Εμείς θα χρησιμοποιήσουμε $a=1$ συνεπώς ο τύπος θα απλοποιηθεί λίγο και θα γίνει:
\begin{eqnarray}
\mbox{Έξοδος} = \frac{1}{1+{e^{-x}}} \label{eq:sigmoids}
\end{eqnarray}

\section{Σχεδιασμός του Νευρωνικού Δικτύου}
Είπαμε ότι το NN θα έχει τη μορφή του σχήματος \ref{fig:nn} (σελ. \pageref{fig:nn}).  Τώρα πρέπει να δούμε πόσες και τι εισόδους θα έχουμε, και πόσους νευρώνες θα έχουμε στο κρυμμένο επίπεδο και στο επίπεδο των εξόδων.

Ας τα πάρουμε με τη σειρά...

\subsection{Είσοδοι}
Στην πρώτη έκδοση του \eng{TD-Gammon}, η κατάσταση της ταβλιέρας αντιπροσωπεύθηκε στο δίκτυο με έναν σχετικά άμεσο τρόπο που συμπεριλάμβανε λίγη γνώση ταβλιού. Εντούτοις, συμπεριλάμβανε την ουσιαστική γνώση για το πώς τα νευρωνικά δίκτυα λειτουργούν και το πώς οι πληροφορίες παρουσιάζονται καλύτερα σε αυτά. Είναι χρήσιμο να σημειωθεί η ακριβής αντιπροσώπευση που ο \eng{Tesauro} επέλεξε. 

Υπήρχαν συνολικά 198 μονάδες εισόδου στο δίκτυο. Για κάθε θέση στην ταβλιέρα, 4 μονάδες δείχνουν τον αριθμό άσπρων κομματιών στο σημείο. Εάν δεν υπάρχει κανένα άσπρο κομμάτι, τότε και οι 4 μονάδες παίρνουν την τιμή μηδέν. Εάν υπάρχει ένα κομμάτι, τότε η πρώτη μονάδα παίρνει την τιμή 1. Εάν υπάρχουν δύο κομμάτια, τότε και η πρώτη και δεύτερη μονάδα παίρνουν την τιμή 1. Εάν υπάρχουν τρία κομμάτια στο σημείο, τότε οι πρώτες τρεις μονάδες παίρνουν την τιμή 1. Εάν υπάρχουν περισσότερα από τρία κομμάτια, η τέταρτη μονάδα παίρνει και αυτή τιμή, τέτοια που δείχνει τον αριθμό πρόσθετων κομματιών πέρα από τρία. Αφήνοντας το $ν$ να δείξει το συνολικό αριθμό κομματιών στο σημείο, εάν $ν > 3$, τότε η τέταρτη μονάδα παίρνει την τιμή $\frac{ν-3}{2}$. Με τέσσερις μονάδες για το Λευκό και τέσσερις για το Μαύρο σε κάθε ένα από τα 24 σημεία, αυτό έκανε συνολικά 192 μονάδες εισόδου. 

Δύο πρόσθετες μονάδες κωδικοποιούσαν τον αριθμό άσπρων και μαύρων κομματιών που ήταν εκτός μετά από ````χτύπημα'''' (κάθε μια είχε την τιμή $ \frac{ν}{2}$, όπου το $ν$ είναι ο αριθμός κομματιών που έχουν χτυπηθεί) και δύο περισσότερες είσοδοι κωδικοποιούσαν τον αριθμό μαύρων και άσπρων κομματιών που αφαιρέθηκαν επιτυχώς από την ταβλιέρα (αυτά είχαν την τιμή $\frac{ν}{15}$, όπου το $ν$ είναι ο αριθμός κομματιών που είχαν ````μαζευτεί''''). 

Τέλος, δύο μονάδες έδειχναν σε μια δυαδική λογική εάν ήταν σειρά του Λευκού ή του Μαύρου να κινηθεί. 

Η γενική λογική πίσω από αυτές τις επιλογές είναι σαφής. Βασικά, ο \eng{Tesauro} προσπάθησε να αντιπροσωπεύσει την κατάσταση με έναν πολύ απλό τρόπο, χωρίς ιδιαίτερη προσπάθεια να ελαχιστοποιηθεί ο αριθμός μονάδων. Παρείχε μια μονάδα για κάθε εννοιολογικά ευδιάκριτη οντότητα που φάνηκε πιθανή να είναι σχετική, προσπαθώντας κάθε μονάδα να βρίσκεται σε ένα πεδίο τιμών μεταξύ 0 και 1.

Ας δούμε τώρα πως μπορούμε να διαφοροποιήσουμε αυτή την κωδικοποίηση του \eng{Tesauro} στα τρία επιμέρους παιχνίδια που απαρτίζουν το ελληνικό τάβλι.
\begin{itemize}
\item Πόρτες: Δεν θα χρειαστεί καμία διαφοροποίηση! (192 είσοδοι)
\item Πλακωτό: Εδώ δεν χρειάζονται δύο μονάδες για τα ````χτυπημένα'''' πούλια, αλλά θα χρειαστεί πέντε (αντί τέσσερα) για κάθε θέση. Η παραπάνω είσοδος θα δηλώνει αν έχει επιτευχθεί ````αιχμαλωτισμός\,'''' του αντιπάλου. (244 είσοδοι)
\item Φεύγα: Πάλι γλιτώνουμε δύο μονάδες για τα ````χτυπημένα'''' πούλια, και αντί για τέσσερα μπορούμε να πέσουμε σε δύο μονάδες ανά παίκτη ανά θέση. Η δεύτερη μονάδα σε κάθε θέση θα είναι διάφορη του μηδέν όταν υπάρχουν περισσότερα του ενός πούλια και η τιμή της θα είναι $\frac{ν-1}{2}$, αν $ν$ το πλήθος των πουλιών στη θέση αυτή. (100 είσοδοι)
\end{itemize}
\subsection{Πόσους νευρώνες?}
Έχουμε τις εισόδους, και τώρα πρέπει να τις δώσουμε στους νευρώνες του \emph{κρυμμένου επιπέδου \eng{(hiden layer)}}.  Πόσους νευρώνες θα έχει το επίπεδο αυτό?  Δεν υπάρχει σίγουρη μέθοδος υπολογισμού, στην ουσία μόνο με δοκιμές θα μπορούμε να καταλάβουμε αν δουλεύει το μοντέλο ή όχι.

Μπορούμε όμως να δούμε πόσους νευρώνες χρησιμοποίησε ο \eng{Tesauro}.  Στην πρώτη έκδοση, έβαλε 40 νευρώνες,στην δεύτερη 80 και στην τρίτη 160.

Συνεπώς, θα αρχίσουμε με 40 νευρώνες και θα δούμε πως θα πάει...
\subsection{Έξοδοι}
Ο \eng{Tesauro} χρησιμοποίησε τρεις εξόδους. Μία έξοδος έδινε την πιθανότητα να κερδηθεί το παιχνίδι, η δεύτερη έξοδος την πιθανότητα νίκης για διπλό παιχνίδι\footnote{Διπλό ονομάζεται το παιχνίδι όταν η μία πλευρά έχει αφαιρέσει επιτυχώς όλα τα πούλια της και η άλλη μεριά δεν έχει αφαιρέσει ούτε ένα}, ενώ η τρίτη την πιθανότητα νίκης για τριπλό παιχνίδι\footnote{Τριπλό ονομάζεται το παιχνίδι όταν η μία πλευρά έχει αφαιρέσει επιτυχώς όλα τα πούλια της και η άλλη μεριά δεν έχει καταφέρει να πάρει όλα τα πούλια της από την περιοχή που \emph{μαζεύει} η πρώτη μεριά}.

Εμείς θα έχουμε δύο εξόδους, αφού στο ελληνικό τάβλι δεν υπάρχει η έννοια του \emph{τριπλού} παιχνιδιού...

\chapter{Εκπαίδευση!}

\section{\eng{Gnubg}}
Το εξαιρετικό\footnote{Δυστυχώς παίζει μόνο πόρτες, αλλιώς δεν θα παιδευόμασταν τώρα...} πρόγραμμα \eng{Gnubg} βασίζεται στην τεχνική \eng{Temporal Difference Learning}. Ας ρίξουμε μια ματιά πως εκπαιδεύει το ΝΝ.
\begin{Πρόγραμμα}
\selectlanguage{english}
\begin{small}
\begin{lstlisting} 
extern void CommandTrainTD( char *sz ) {
  int anBoardTrain[ 2 ][ 25 ], anBoardOld[ 2 ][ 25 ];
  int anDiceTrain[ 2 ],c = 0, n;
  float ar[ NUM_OUTPUTS ];

  while( ( !n || c <= n ) && !fInterrupt ) {
    InitBoard( anBoardTrain, ciCubeless.bgv );
    do {    
      RollDice( anDiceTrain, rngCurrent, rngctxCurrent );
      memcpy(anBoardOld, anBoardTrain, sizeof(anBoardOld));
      FindBestMove(NULL,anDiceTrain[0],anDiceTrain[1],
        anBoardTrain,&ciCubeless,&ecTD,defaultFilters);
      SwapSides( anBoardTrain );
      EvaluatePosition(anBoardTrain,ar,&ciCubeless,&ecTD);
      InvertEvaluation( ar );@\label{ln:temp}`
      if( TrainPosition( anBoardOld, ar, rAlpha, rAnneal,@\label{vrb:train}`
                                       ciCubeless.bgv ) )
        break;
    } while( ( !n || c <= n ) && !fInterrupt &&
      !GameStatus( anBoardTrain, ciCubeless.bgv ) );
  }
}
\end{lstlisting}
\end{small}
\selectlanguage{greek}
  \caption{ - Εκπαίδευση στο \eng{gnubg}}
  \label{prg2}
\end{Πρόγραμμα}

Η γενική ιδέα της εκπαίδευσης είναι να παίζει το ΝΝ συνέχεια με τον εαυτό του, σε κάθε κίνηση μεταβάλλει τα βάρη και συνεχίζει. Με ποια λογική τώρα μεταβάλλει τα βάρη?  Έστω ότι είμαστε στην κατάσταση ταβλιέρας $s_0$, καταρχήν βρίσκει όλες τις επιτρεπτές κινήσεις. Για κάθε επιτρεπτή κίνηση \emph{προσποιείται} ότι την κάνει και στην συνέχεια περνάει την κατάσταση της ταβλιέρας $s_i$ ($i=1 \ldots n$, αν $n$ το πλήθος των επιτρεπτών κινήσεων) ως είσοδο στο ΝΝ.  Το ΝΝ υπολογίζει την τιμή των εξόδων $Ε_0$ και $Ε_1$ (θυμηθείτε ότι η $Ε_0$ δίνει την πιθανότητα νίκης μονού παιχνιδιού, ενώ η $Ε_1$ την πιθανότητα νίκης διπλού παιχνιδιού).  Από όλες τις επιτρεπτές κινήσεις επιλέγει την κίνηση με τη μεγαλύτερη πιθανότητα νίκης ($max(E_0)$).  

Αφού βρει την \emph{καλύτερη} κίνηση, τότε παίζει την κίνηση αυτή και φέρνει την ταβλιέρα στην επόμενη κατάσταση $s_1$.  Έχουμε λοιπόν την ````παλιά'''' θέση $s_0$ που αν την δώσουμε είσοδο στο ΝΝ, παίρνουμε $Y_0$ στις εξόδους, και την ````νέα'''' θέση $s_1$ που δίνει $Y_1$ στις εξόδους.  Η διαφορά των εξόδων $(Y_1-Y_0)$ δίνει το ````λάθος\,'''', βάσει του οποίου μπορούμε να κάνουμε τις διορθώσεις στα βάρη (γραμμή \ref{vrb:train}).

Βέβαια οι αρχικές τιμές των βαρών είναι ψευδοτυχαίες, και συνεπώς οι καλύτερες κινήσεις που βρίσκει αρχικά το ΝΝ είναι εντελώς τυχαίες (δηλ. σκουπίδια).  Σταδιακά όμως το μοντέλο συγκλίνει σε βάρη που είναι ικανά να αξιολογήσουν σωστά την κατάσταση της ταβλιέρας. Ενδεικτικά, στην πρώτη προσπάθεια του \eng{Tesauro} χρειάστηκαν 200.000 παιχνίδια προκειμένου να \emph{κουρδιστούν} αξιοπρεπώς τα βάρη.
\end{document}          
